{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12556319,
          "sourceType": "datasetVersion",
          "datasetId": 7928457
        },
        {
          "sourceId": 12582078,
          "sourceType": "datasetVersion",
          "datasetId": 7938602
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "model = RTDETR(\"/kaggle/working/best.pt\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-26T09:52:28.372909Z",
          "iopub.execute_input": "2025-07-26T09:52:28.373216Z",
          "iopub.status.idle": "2025-07-26T09:52:28.641731Z",
          "shell.execute_reply.started": "2025-07-26T09:52:28.373196Z",
          "shell.execute_reply": "2025-07-26T09:52:28.640891Z"
        },
        "id": "ya8AQlQsl4Qp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#–û–±—É—á–µ–Ω–∏–µ\n",
        "results = model.train(\n",
        "    data=YAML_PATH,\n",
        "    epochs=25,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    device=0,\n",
        "    workers=4,\n",
        "    name=\"rtdetr_train_final\",\n",
        "    val=True,       # –æ—Ç–∫–ª—é—á–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é\n",
        "    save=True,\n",
        "    save_period=5,\n",
        "    plots=False\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-26T09:53:07.784732Z",
          "iopub.execute_input": "2025-07-26T09:53:07.785333Z"
        },
        "id": "KUWUN79vl4Qq",
        "outputId": "5026011b-a879-4aff-8cd3-7045de06d877"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Ultralytics 8.3.169 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=rtdetr_train_final, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/rtdetr_train_final, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\nWARNING ‚ö†Ô∏è no model scale passed. Assuming scale='l'.\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \nrt-detr-l summary: 457 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n\nTransferred 941/941 items from pretrained weights\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 109MB/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 57.3¬±17.8 MB/s, size: 3260.6 KB)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train/labels... 3946 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3946/3946 [00:06<00:00, 657.19it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1796.8¬±1580.2 MB/s, size: 3198.9 KB)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val/labels... 694 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 694/694 [00:00<00:00, 1376.78it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/val/labels.cache\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/rtdetr_train_final\u001b[0m\nStarting training for 25 epochs...\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/494 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       1/25       7.5G     0.6503     0.5186    0.05526          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [06:21<00:00,  1.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:29<00:00,  1.50it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "                   all        694        775      0.794      0.676      0.744      0.407\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/494 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       2/25       7.1G     0.6282     0.5067    0.05064          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [06:02<00:00,  1.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:28<00:00,  1.56it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "                   all        694        775      0.791      0.621      0.682      0.357\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/494 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       3/25      7.97G     0.6228     0.5033    0.05024          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [05:55<00:00,  1.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:28<00:00,  1.53it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "                   all        694        775      0.855      0.748      0.807      0.454\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/494 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       4/25      7.11G     0.6101     0.4902    0.04752          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [05:54<00:00,  1.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:27<00:00,  1.60it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "                   all        694        775      0.891      0.748      0.846      0.488\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/494 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       5/25       7.2G     0.5971     0.4859    0.04803          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [05:51<00:00,  1.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:23<00:00,  1.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "                   all        694        775       0.85      0.729      0.808      0.463\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/494 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       6/25      7.29G     0.5962     0.4857    0.04698          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [05:52<00:00,  1.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:28<00:00,  1.54it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "                   all        694        775      0.906      0.793       0.87      0.511\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/494 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       7/25      7.32G     0.6028     0.4746    0.04773          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494/494 [05:54<00:00,  1.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  23%|‚ñà‚ñà‚ñé       | 10/44 [00:03<00:13,  2.55it/s]",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /kaggle/working/save\n",
        "!cp -r /kaggle/working/runs /kaggle/working/save/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-25T11:00:16.997087Z",
          "iopub.execute_input": "2025-07-25T11:00:16.997954Z",
          "iopub.status.idle": "2025-07-25T11:00:18.562082Z",
          "shell.execute_reply.started": "2025-07-25T11:00:16.997921Z",
          "shell.execute_reply": "2025-07-25T11:00:18.561154Z"
        },
        "id": "UL2lVVZWl4Qq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /kaggle/working/checkpoint_part1.zip /kaggle/working/save"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-25T11:00:20.979925Z",
          "iopub.execute_input": "2025-07-25T11:00:20.980804Z",
          "iopub.status.idle": "2025-07-25T11:01:07.581721Z",
          "shell.execute_reply.started": "2025-07-25T11:00:20.980771Z",
          "shell.execute_reply": "2025-07-25T11:01:07.580930Z"
        },
        "id": "Kp6Y6zUAl4Qr",
        "outputId": "616f3ffc-efad-419e-bdb6-e2740ade2739"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "  adding: kaggle/working/save/ (stored 0%)\n  adding: kaggle/working/save/runs/ (stored 0%)\n  adding: kaggle/working/save/runs/detect/ (stored 0%)\n  adding: kaggle/working/save/runs/detect/rtdetr_train_final/ (stored 0%)\n  adding: kaggle/working/save/runs/detect/rtdetr_train_final/weights/ (stored 0%)\n  adding: kaggle/working/save/runs/detect/rtdetr_train_final/weights/epoch20.pt (deflated 56%)\n  adding: kaggle/working/save/runs/detect/rtdetr_train_final/weights/epoch15.pt (deflated 56%)\n  adding: kaggle/working/save/runs/detect/rtdetr_train_final/weights/epoch0.pt (deflated 55%)\n  adding: kaggle/working/save/runs/detect/rtdetr_train_final/weights/epoch25.pt^C\n\n\n\nzip error: Interrupted (aborting)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}